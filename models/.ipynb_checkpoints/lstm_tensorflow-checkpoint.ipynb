{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../mined_data/anekdot_ru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вставай, страна огромная, салаты доедай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Переписка по СМС: - Спартак - чемпион! - После...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>из толерантности закон, защищающий чувства вер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спиваться, когда что-то случилось - это удел б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Неразрешимая дилемма: следует ли на новогоднем...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0           Вставай, страна огромная, салаты доедай.\n",
       "1  Переписка по СМС: - Спартак - чемпион! - После...\n",
       "2  из толерантности закон, защищающий чувства вер...\n",
       "3  Спиваться, когда что-то случилось - это удел б...\n",
       "4  Неразрешимая дилемма: следует ли на новогоднем..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67024, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only unique anekdots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.unique(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63961,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only anekdots with length > MIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  530.,  6022., 10926., 10668.,  8517.,  6150.,  4074.,  3056.,\n",
       "         2327.,  1780.]),\n",
       " array([  7. ,  36.2,  65.4,  94.6, 123.8, 153. , 182.2, 211.4, 240.6,\n",
       "        269.8, 299. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in anekdots_array if len(x) < 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.array([re.sub(r'[^\\w\\s]','', x.lower()) for x in anekdots_array if len(x) > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44146,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple whitespaces to one whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [' '.join(x.split()) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if not i.isdigit()]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if i not in ['ل', 'ت', 'ї', 'د', 'ي', 'ه', 'ن', 'є', 'é', 'ر', 'ة', 'ب', 'إ','أ', 'ү', 'љ', 'ђ', 'ذ', 'س', 'ñ', 'ك', 'ى', 'م', 'و', 'š', 'č','ü', 'ö', 'ح', 'v', 'g', 'f', '_', 'b', 'x', 'j', 'z', 'q', 'і', 'ø', 'ë', 'ا', 'i', 't', 'r', 'n', 's', 'c', 'u', 'l', 'w', 'm', 'd', 'k', 'a', 'y', 'o', 'e', 'h', 'p']]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(' '.join(anekdots_array))))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  10360647\n",
      "Total Vocab:  34\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(' '.join(anekdots_array))\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[' ', 'о', 'а', 'е', 'т', 'и', 'н', 'с', 'р', 'в', 'л', 'к', 'д',\n",
       "        'м', 'у', 'п', 'я', 'ь', 'ы', 'б', 'г', 'з', 'ч', 'й', 'ж', 'ш',\n",
       "        'х', 'ю', 'ц', 'щ', 'э', 'ф', 'ё', 'ъ'],\n",
       "       ['1694800', '896843', '759521', '727190', '603989', '587053',\n",
       "        '521226', '433051', '391734', '387513', '342506', '325462',\n",
       "        '287641', '277041', '276782', '256867', '172096', '159765',\n",
       "        '154580', '143371', '143272', '141493', '140778', '107879',\n",
       "        '95550', '81075', '72694', '58629', '36566', '27933', '26381',\n",
       "        '19298', '6974', '3094']], dtype='<U21')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(np.unique([x for x in ' '.join(anekdots_array)], return_counts=True))\n",
    "a[:, a[1].astype(int).argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  9212852\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for anekdot in anekdots_array:\n",
    "    for i in range(0, len(anekdot) - SEQ_LEN, 1):\n",
    "        seq_in = anekdot[i:i + SEQ_LEN]\n",
    "        seq_out = anekdot[i + SEQ_LEN]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "        \n",
    "        \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9212852\n",
      "9212852\n",
      "[3, 0, 11, 1, 14, 23, 6, 12, 32, 17, 9, 31, 0, 16, 17, 6, 8, 9, 5, 6, 14, 19, 1, 0, 20]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataY))\n",
    "print(dataX[0])\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, SEQ_LEN, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBatchLogger(Callback):\n",
    "    def __init__(self, display=10):\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            start = numpy.random.randint(0, len(dataX)-1)\n",
    "            pattern = dataX[start]\n",
    "            print(\"Seed:\")\n",
    "            print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"|\", end=\"\", flush=True)\n",
    "            # generate characters\n",
    "            for i in range(300):\n",
    "                x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "                x = x / float(n_vocab)\n",
    "                prediction = model.predict(x, verbose=0)\n",
    "                index = np.where(prediction[0] == np.random.choice(prediction[0], p=(prediction[0]/np.sum(prediction[0]))))[0][0]\n",
    "#                 index = numpy.argmax(prediction)\n",
    "                result = int_to_char[index]\n",
    "                seq_in = [int_to_char[value] for value in pattern]\n",
    "                print(result, end=\"\", flush=True)\n",
    "                pattern.append(index)\n",
    "                pattern = pattern[1:len(pattern)]\n",
    "            print(\"\\\"\")\n",
    "            print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = NBatchLogger(display=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 381440/9212852 [>.............................] - ETA: 2:58:07 - loss: 2.2753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-cf05f6aba9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=512, callbacks=[out_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" продлить ваше бессмыслен| с обп лолали работете там и от а неклого спяшость у эти падютнательна инэ чанет афигя хупям все ковоутся я почемя фртроала ладо зав бад мино водетстнууся сара неатибчим ну в гручт рытон ссобну потебихся хы побобели когройемащу тибуить ття реда сасе вмрт хдрон на вонловннелейапде бознолорлнож робали"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\" + ''.join([int_to_char[value] for value in pattern]) + \"|\", end=\"\", flush=True)\n",
    "# generate characters\n",
    "for i in range(300):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.where(prediction[0] == np.random.choice(prediction[0], p=(prediction[0]/np.sum(prediction[0]))))[0][0]\n",
    "#     index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end=\"\", flush=True)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    raw_text = f.read().lower()\n",
    "print('corpus length:', len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  600893\n",
      "Total Vocab:  57\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  600793\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600793\n",
      "600793\n",
      "[42, 44, 31, 32, 27, 29, 31, 0, 0, 0, 45, 47, 42, 42, 41, 45, 35, 40, 33, 1, 46, 34, 27, 46, 1, 46, 44, 47, 46, 34, 1, 35, 45, 1, 27, 1, 49, 41, 39, 27, 40, 8, 8, 49, 34, 27, 46, 1, 46, 34, 31, 40, 23, 1, 35, 45, 1, 46, 34, 31, 44, 31, 1, 40, 41, 46, 1, 33, 44, 41, 47, 40, 30, 0, 32, 41, 44, 1, 45, 47, 45, 42, 31, 29, 46, 35, 40, 33, 1, 46, 34, 27, 46, 1, 27, 38, 38, 1, 42, 34]\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataY))\n",
    "print(dataX[0])\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(None, X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = NBatchLogger(display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   640/600793 [..............................] - ETA: 1:04:05 - loss: 3.9716Seed:\n",
      "\" !?P?LSQB?L?!NB;N!MF;P?(GIL;FCNS!A;CHM!NB?!;M=?H>;H=S'!F;HAO;A? MBIQM!;!N?H>?H=S!NI!;JJLIRCG;N?!NB?!M!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  1280/600793 [..............................] - ETA: 1:24:49 - loss: 3.7020Seed:\n",
      "\" HI!FIHA?L!@??FM!;HS!CHN?L?MN!CH!;!NBCHA&)!@ILG?LFS NB?!GCH>!Q;M!HIN!<LIOABN!CHNI!JF;S!NBLIOAB!NB?!G?!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  1920/600793 [..............................] - ETA: 1:23:16 - loss: 3.5168Seed:\n",
      "\" ?!JLI@IOH>'!MOMJC=CIOM!@?;L!I@!;H!CH=OL;<F? J?MMCGCMG!QBC=B!=IGJ?FM!QBIF?!=?HNOLC?M!NI!@;MN?H!NB?CL!IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\"\n",
      "\n",
      "Done.\n",
      "  2560/600793 [..............................] - ETA: 1:21:37 - loss: 3.4299Seed:\n",
      "\" N!I@!IH?$M!IQH!?RJ?LC?H=?((?RJ?LC?H=?'!;M!CN!M??GM!NI!G?'!;FQ;SM CGJFC?M!OH@ILNOH;N?!?RJ?LC?H=?7((NI!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  3200/600793 [..............................] - ETA: 1:20:43 - loss: 3.3588Seed:\n",
      "\" !FIHA!NCG?!=B;CH?>!OJ)!L;NB?L!GOMN!;!G;H'!@LIG!QBIG!NB?!IL>CH;LS <IH>;A?M!I@!FC@?!B;P?!@;FF?H!;Q;S!N!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  3840/600793 [..............................] - ETA: 1:20:08 - loss: 3.3162Seed:\n",
      "\" BIF?!I<?>C?H=?!B;>!<??H!@IL?MQILH'!QCNBION'!BIQ?P?L'!NB?!MJ?FF!I@!BCM M=ILH@OF!?MNCG;N?M!I@!INB?L!JB!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  4480/600793 [..............................] - ETA: 1:19:49 - loss: 3.2842Seed:\n",
      "\" F;N?L!@L?H=B!LIG;HNC=CMG!I@!NB?!@ILNC?M'!;L? GIMN!=FIM?FS!;H>!CHNCG;N?FS!L?F;N?>!NI!IH?!;HINB?L)!NB?!!!!!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?!!!!!!!?\"\n",
      "\n",
      "Done.\n",
      "  5120/600793 [..............................] - ETA: 1:20:31 - loss: 3.2507Seed:\n",
      "\" !NI!<?;L!NB?!Q?CABN!I@!MO=B!L?MJIHMC<CFCNS5 ;H>!IH!NB?!INB?L!B;H>!NB?!H?=?MMCNS!@IL!MO=B!F?;>?LM'!NB!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  5760/600793 [..............................] - ETA: 1:21:09 - loss: 3.2287Seed:\n",
      "\" NCP;N?!NB? @IL?CAH!?;L!;M!Q?FF!;M!NB?!H;NCP?((NBCM!<IIE!B;M!<??H!L?;>!GIMN CH>C@@?L?HNFS!CH!A?LG;HS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  6400/600793 [..............................] - ETA: 1:21:55 - loss: 3.2100Seed:\n",
      "\" HI=?H=?!I@!NBCHE?LM!B;M!MIG?NBCHA!NIO=BCHA!;H> L?MJ?=N(CHMJCLCHA!CH!CN'!QBC=B!?P?H!HIQ;>;SM!J?LGCNM!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  7040/600793 [..............................] - ETA: 1:22:04 - loss: 3.1980Seed:\n",
      "\"   +1.)!S?!ONCFCN;LC;HM((S?'!NII'!FIP?!NB?!ONCF?!IHFS!;M!;!P?BC=F?!@IL SIOL!CH=FCH;NCIHM'((S?'!NII'!L!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  7680/600793 [..............................] - ETA: 1:21:42 - loss: 3.1865Seed:\n",
      "\" !I@!NB?!MI(=;FF?>!GIL;F!@??FCHAM ;H>!QBC=B'!CH!CNM!JLIAL?MM'!CM!=;FF?>!OJIH!NI!JIMCN!;H>!NI!MIFP? ;>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  8320/600793 [..............................] - ETA: 1:21:30 - loss: 3.1758Seed:\n",
      "\" CM >??G?>!JIMMC<F?!NI!NB?!?RN?HN!NB;N!CN!CM!>?MCL?>!IL!@?;L?>)!NB? #JL?M?HNCG?HN#!CM!HIN!IH?!MN?J!@I!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  8960/600793 [..............................] - ETA: 1:21:08 - loss: 3.1648Seed:\n",
      "\" CN!=;H IHFS!>I!MI!;M!;!@ILG!I@!FOROLS'!;M!;H!;L=B;CTCHA!N;MN?)!P;LC;NCIHM' QB?NB?L!NB?S!<?!>?PC;NCIH!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      "  9600/600793 [..............................] - ETA: 1:20:51 - loss: 3.1572Seed:\n",
      "\" H IHFS!>I!MI!;M!;!@ILG!I@!FOROLS'!;M!;H!;L=B;CTCHA!N;MN?)!P;LC;NCIHM' QB?NB?L!NB?S!<?!>?PC;NCIHM!%CH!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      " 10240/600793 [..............................] - ETA: 1:20:49 - loss: 3.1528Seed:\n",
      "\" CH?>!@IL!=IHKO?LCHA ;H>!=CL=OGP?HNCHA!INB?LM'!NB?!@CH?MN!?R;GJF?M!I@!QBC=B!;L?!;F=C<C;>?M ;H>!=;?M;L!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      " 10880/600793 [..............................] - ETA: 1:20:34 - loss: 3.1480Seed:\n",
      "\" '!MQCHA'!=IOL;A?'!;H>!;LNCMNC=!JIQ?L'!;H>!NB?S!QIOF>!<?!I@@((;H> HIN!<;=E\"  ++)!CN!M??GM!NI!G?!NB;N!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "Done.\n",
      " 11264/600793 [..............................] - ETA: 1:22:13 - loss: 3.1446"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-71262157ddd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=[out_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
