{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../mined_data/anekdot_ru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вставай, страна огромная, салаты доедай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Переписка по СМС: - Спартак - чемпион! - После...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>из толерантности закон, защищающий чувства вер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спиваться, когда что-то случилось - это удел б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Неразрешимая дилемма: следует ли на новогоднем...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0           Вставай, страна огромная, салаты доедай.\n",
       "1  Переписка по СМС: - Спартак - чемпион! - После...\n",
       "2  из толерантности закон, защищающий чувства вер...\n",
       "3  Спиваться, когда что-то случилось - это удел б...\n",
       "4  Неразрешимая дилемма: следует ли на новогоднем..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67024, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only unique anekdots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.unique(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63961,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only anekdots with length > MIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  530.,  6022., 10926., 10668.,  8517.,  6150.,  4074.,  3056.,\n",
       "         2327.,  1780.]),\n",
       " array([  7. ,  36.2,  65.4,  94.6, 123.8, 153. , 182.2, 211.4, 240.6,\n",
       "        269.8, 299. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in anekdots_array if len(x) < 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.array([re.sub(r'[^\\w\\s]','', x.lower()) for x in anekdots_array if len(x) > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44146,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple whitespaces to one whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [' '.join(x.split()) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if not i.isdigit()]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if i not in ['ل', 'ت', 'ї', 'د', 'ي', 'ه', 'ن', 'є', 'é', 'ر', 'ة', 'ب', 'إ','أ', 'ү', 'љ', 'ђ', 'ذ', 'س', 'ñ', 'ك', 'ى', 'م', 'و', 'š', 'č','ü', 'ö', 'ح', 'v', 'g', 'f', '_', 'b', 'x', 'j', 'z', 'q', 'і', 'ø', 'ë', 'ا', 'i', 't', 'r', 'n', 's', 'c', 'u', 'l', 'w', 'm', 'd', 'k', 'a', 'y', 'o', 'e', 'h', 'p']]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(' '.join(anekdots_array))))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  10360647\n",
      "Total Vocab:  34\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(' '.join(anekdots_array))\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[' ', 'о', 'а', 'е', 'т', 'и', 'н', 'с', 'р', 'в', 'л', 'к', 'д',\n",
       "        'м', 'у', 'п', 'я', 'ь', 'ы', 'б', 'г', 'з', 'ч', 'й', 'ж', 'ш',\n",
       "        'х', 'ю', 'ц', 'щ', 'э', 'ф', 'ё', 'ъ'],\n",
       "       ['1694800', '896843', '759521', '727190', '603989', '587053',\n",
       "        '521226', '433051', '391734', '387513', '342506', '325462',\n",
       "        '287641', '277041', '276782', '256867', '172096', '159765',\n",
       "        '154580', '143371', '143272', '141493', '140778', '107879',\n",
       "        '95550', '81075', '72694', '58629', '36566', '27933', '26381',\n",
       "        '19298', '6974', '3094']], dtype='<U21')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(np.unique([x for x in ' '.join(anekdots_array)], return_counts=True))\n",
    "a[:, a[1].astype(int).argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  7669415\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for anekdot in anekdots_array:\n",
    "    for i in range(0, len(anekdot) - SEQ_LEN, 1):\n",
    "        seq_in = anekdot[i:i + SEQ_LEN]\n",
    "        seq_out = anekdot[i + SEQ_LEN]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "        \n",
    "        \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7669415\n",
      "7669415\n",
      "[3, 0, 11, 1, 14, 23, 6, 12, 32, 17, 9, 31, 0, 16, 17, 6, 8, 9, 5, 6, 14, 19, 1, 0, 20, 11, 17, 1, 9, 14, 28, 0, 3, 0, 1, 0, 31, 26, 6, 14, 11, 15, 0, 8, 1, 32, 3, 12, 6, 14, 9, 6, 0, 20, 3, 0, 3, 9, 11, 19]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataY))\n",
    "print(dataX[0])\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (7669415, 60, 34)\n",
      "y.shape: (7669415, 34)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the input data\n",
    "X = np_utils.to_categorical(dataX)\n",
    "print(\"X.shape: {}\".format(X.shape))\n",
    "# one hot encode the output data\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print(\"y.shape: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(pattern):\n",
    "    result = np.zeros((1, len(pattern), len(int_to_char)))\n",
    "    for ix, i in enumerate(pattern):\n",
    "        result[0, ix, i] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(32))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBatchLogger(Callback):\n",
    "    def __init__(self, display=10):\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            start = numpy.random.randint(0, len(dataX)-1)\n",
    "            pattern = dataX[start]\n",
    "            print(\"Seed:\")\n",
    "            print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"|\", end=\"\", flush=True)\n",
    "            # generate characters\n",
    "            for i in range(300):\n",
    "                x = list_to_df(pattern)\n",
    "                prediction = model.predict(x, verbose=0)\n",
    "#                 index = np.where(prediction[0] == np.random.choice(prediction[0], p=(prediction[0]/np.sum(prediction[0]))))[0][0]\n",
    "                index = np.random.choice(np.argsort(prediction[0])[-3:])\n",
    "#                 index = np.argmax(prediction)\n",
    "                \n",
    "                result = int_to_char[index]\n",
    "                seq_in = [int_to_char[value] for value in pattern]\n",
    "                print(result, end=\"\", flush=True)\n",
    "                pattern.append(index)\n",
    "                pattern = pattern[1:len(pattern)]\n",
    "            print(\"\\\"\")\n",
    "            print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = NBatchLogger(display=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  40000/7669415 [..............................] - ETA: 8:06:56 - loss: 2.2656Seed:\n",
      "\" жу весло на плечо и буду идти в направлении от берега до тех |о скровитсьско вы скристе водитьсьнойскийся продоват с собильнаясьско начинойсто не восем презали содног продотали странаюссяст ново в строва содей предесле на песломинаюсс с водов вотри собола вы скровой пристоломо спосли согриннойнитесь старитьние соменныески пестре ногра наченик спарил продивае п\"\n",
      "\n",
      "Done.\n",
      "  80000/7669415 [..............................] - ETA: 8:23:53 - loss: 2.2375Seed:\n",
      "\" осил как там дела абдулла сказал что все вежливы и вниматель |сков дера скродите но воде вых следи палат потраствовит сладильсясь всталь слодать с выс вытоме постал но вым поскурениясятсятьный вским вскама и пристильныем стово него с потрами выторомиником петьме слово скрогаяте пате подамитете строга ногразитест ногора с потом встровит потово сладоват с выму п\"\n",
      "\n",
      "Done.\n",
      " 120000/7669415 [..............................] - ETA: 8:38:09 - loss: 2.2194Seed:\n",
      "\"  эффективнее газовый ключ или газовая тба  канал анекдотланд |ит в постов педередил неденьскаятсьски продитель сога пестилиски пристините поседи содителиновос воденик в стана семя поседате нето воздал нетоме вот ного вы встомина в сталь провосленае в собал не водитстев вотро надератьсят не сомана придитькийникогаяннойни сомат в столинов в песле правадат новыми\"\n",
      "\n",
      "Done.\n",
      " 160000/7669415 [..............................] - ETA: 51:52:58 - loss: 2.2009Seed:\n",
      "\" ему бог украл к адама ребро и сделал из него женщину он хоте |шейниесь присловаеща в продими нете вытераетесь водит собать накак пеля с нег песлидит в дерей слодитсьсятесковос выдоройне с накаемино на себяте недеройнойном в дом накийной воритиланиемустер воредин вот пристила с половитеся воднейныетстение прислеши наканите с нем стоятелька солода серчитскиесь с\"\n",
      "\n",
      "Done.\n",
      " 200000/7669415 [..............................] - ETA: 43:05:04 - loss: 2.1829Seed:\n",
      "\"  коллектив редакции газеты дона от всей души поздравляет с д |а песединам непревит всямаястет насовались на переми пеский станаясь сонила предлежны наваните всемил нет первойтом всямие совонниесьной все в передина сабет перимати не старо предервовниемиесьно в дарими собенные сто с соменяе выхорилиствитьно петьемую пресловит провослийскомият присло простолись п\"\n",
      "\n",
      "Done.\n",
      " 240000/7669415 [..............................] - ETA: 37:14:30 - loss: 2.1679Seed:\n",
      "\" завтрашнего дня не пью не курю и занимаюсь сексом только со  |насти начасьных сомато с старато подно песто нудамат испатилийски ну пода подулатьсясьстваяст и продал придитьелиясьной всем с нихсействан прасите водно вытромали полета в пестанно просит строват полемат искотькийакие прода вы спровели на семенят сотака поту прослостви петьсте предилося надов начано\"\n",
      "\n",
      "Done.\n",
      " 280000/7669415 [>.............................] - ETA: 33:01:06 - loss: 2.1544Seed:\n",
      "\" убы жди эпидемии если ёлки то на новый год большое гулянье б |ологами в сользам новейскамис пари но негдарони пала него стораннико подульте вы нетелести всяк изветие новог ами с ското полочку начинут водо пально носковором вотреринойстрино продли предиду всегденив подоривиется идитьно парова поседен иза насторовительсь нетог авто подумут получить новое палиции\"\n",
      "\n",
      "Done.\n",
      " 320000/7669415 [>.............................] - ETA: 29:50:07 - loss: 2.1430Seed:\n",
      "\" просто в отчаянии сегодня я пошел к доктору чтобы он выписал | в присил надильникемникованияте с них возваниет вотстваласьноемуд подораться в тебятой в толкай выстанотыл вотовала по получе ноговироматьно не сотолька пастатыми недняют принялас послет вотова новатьстверно новые вот воздалаясьсьсясьноет водельник в получаем но правел ваши ногрос паре с седят прот\"\n",
      "\n",
      "Done.\n",
      " 360000/7669415 [>.............................] - ETA: 27:20:50 - loss: 2.1310Seed:\n",
      "\"  почему же верю верю что вы пошли в ресторан верю что были у |живает преплатат проборнил ну приситьки прихришателискиесьственноскойничеко высловит страль полут в притина пробелителе пельцино продеральногом правлениисятьски ими нетаникому испотил на скора примарин нушкура водимуютсь полит палани по проботьюмимующаемиении полужногри в потратиль но стралили водин\"\n",
      "\n",
      "Done.\n",
      " 400000/7669415 [>.............................] - ETA: 25:29:46 - loss: 2.1179Seed:\n",
      "\"  класс ты можешь вставить колечки и повесить занавеску квн с |лужайт послучаешьсь в послуче подаваемел в подавил сторатьниц возвон прездолодить станойногот на полет ну надовили станили пара продар прездаем получениямильсьсят новыми с себеники постивить в карати пастаритьсятство выписели презаверникому в петеле посло негратиль вы вышиваютестви все подувит надал\"\n",
      "\n",
      "Done.\n",
      " 440000/7669415 [>.............................] - ETA: 23:49:48 - loss: 2.1075Seed:\n",
      "\" черт его знает какие на марсе условия жизни ну а выживут там |и с песениясьнойстравныйто соненатыр проберен в корминамом петределия выперили всему полет полезит проста возмельнойскийтиром в кактини презисталов исторните все предержен придоском переда на присематились полечит петромул и прости встолен приносто выпрода предеслатныесятьстив стрито при в солосом п\"\n",
      "\n",
      "Done.\n",
      " 480000/7669415 [>.............................] - ETA: 33:31:50 - loss: 2.0975Seed:\n",
      "\" те поднять на  кг больше доспехов надоело работать получай о |брымилаясьсь непеседаятеле папет прездала в крыва вся надра надру неприветили паретать новоейника выпрешив пальце собрена посмашел в комарони преслетниеся вся встакаты вся подумаешь вотрать встрочает насказатель пататер подумитесь на прикак непелетер папен пели не возмал высторниковатьсьсят папе пар\"\n",
      "\n",
      "Done.\n",
      " 515456/7669415 [=>............................] - ETA: 34:47:35 - loss: 2.0884"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e77f8f12312d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=[out_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\" + ''.join([int_to_char[value] for value in pattern]) + \"|\", end=\"\", flush=True)\n",
    "# generate characters\n",
    "for i in range(300):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.where(prediction[0] == np.random.choice(prediction[0], p=(prediction[0]/np.sum(prediction[0]))))[0][0]\n",
    "#     index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end=\"\", flush=True)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../mined_data/anekdot_ru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вставай, страна огромная, салаты доедай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Переписка по СМС: - Спартак - чемпион! - После...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>из толерантности закон, защищающий чувства вер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спиваться, когда что-то случилось - это удел б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Неразрешимая дилемма: следует ли на новогоднем...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0           Вставай, страна огромная, салаты доедай.\n",
       "1  Переписка по СМС: - Спартак - чемпион! - После...\n",
       "2  из толерантности закон, защищающий чувства вер...\n",
       "3  Спиваться, когда что-то случилось - это удел б...\n",
       "4  Неразрешимая дилемма: следует ли на новогоднем..."
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67024, 1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only unique anekdots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.unique(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63961,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave only anekdots with length > MIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  530.,  6022., 10926., 10668.,  8517.,  6150.,  4074.,  3056.,\n",
       "         2327.,  1780.]),\n",
       " array([  7. ,  36.2,  65.4,  94.6, 123.8, 153. , 182.2, 211.4, 240.6,\n",
       "        269.8, 299. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in anekdots_array if len(x) < 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = np.array([re.sub(r'[^\\w\\s]','', x.lower()) for x in anekdots_array if len(x) > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44146,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anekdots_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple whitespaces to one whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [' '.join(x.split()) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if not i.isdigit()]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "anekdots_array = [''.join([i for i in x if i not in ['ل', 'ت', 'ї', 'د', 'ي', 'ه', 'ن', 'є', 'é', 'ر', 'ة', 'ب', 'إ','أ', 'ү', 'љ', 'ђ', 'ذ', 'س', 'ñ', 'ك', 'ى', 'م', 'و', 'š', 'č','ü', 'ö', 'ح', 'v', 'g', 'f', '_', 'b', 'x', 'j', 'z', 'q', 'і', 'ø', 'ë', 'ا', 'i', 't', 'r', 'n', 's', 'c', 'u', 'l', 'w', 'm', 'd', 'k', 'a', 'y', 'o', 'e', 'h', 'p']]) for x in anekdots_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'а', 'андреевич', 'биографию', 'больше', 'в', 'вас', 'виктор',\n",
       "       'вопросами', 'все', 'году', 'городах', 'гривневой', 'грушевскому',\n",
       "       'денту', 'деятельность', 'донецке', 'дядька', 'его', 'за',\n",
       "       'забудьте', 'заебали', 'заявление', 'зидента', 'и', 'избранного',\n",
       "       'изложить', 'историков', 'как', 'канцелярию', 'кратко', 'купюре',\n",
       "       'луганске', 'менте', 'михаилу', 'можно', 'мы', 'на', 'нарисован',\n",
       "       'народной', 'нас', 'не', 'обязательно', 'особенности', 'первому',\n",
       "       'пост', 'поста', 'построить', 'пре', 'прези', 'президента', 'при',\n",
       "       'просим', 'пямятников', 'республики', 'рькове', 'с', 'севастополе',\n",
       "       'селах', 'союз', 'ти', 'то', 'ув', 'уже', 'украинской', 'украины',\n",
       "       'ха', 'частности', 'че', 'этнографов', 'этом', 'этот', 'ющенко'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(anekdots_array[0].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 1/44146\n",
      "Preprocessed 101/44146\n",
      "Preprocessed 201/44146\n",
      "Preprocessed 301/44146\n",
      "Preprocessed 401/44146\n",
      "Preprocessed 501/44146\n",
      "Preprocessed 601/44146\n",
      "Preprocessed 701/44146\n",
      "Preprocessed 801/44146\n",
      "Preprocessed 901/44146\n",
      "Preprocessed 1001/44146\n",
      "Preprocessed 1101/44146\n",
      "Preprocessed 1201/44146\n",
      "Preprocessed 1301/44146\n",
      "Preprocessed 1401/44146\n",
      "Preprocessed 1501/44146\n",
      "Preprocessed 1601/44146\n",
      "Preprocessed 1701/44146\n",
      "Preprocessed 1801/44146\n",
      "Preprocessed 1901/44146\n",
      "Preprocessed 2001/44146\n",
      "Preprocessed 2101/44146\n",
      "Preprocessed 2201/44146\n",
      "Preprocessed 2301/44146\n",
      "Preprocessed 2401/44146\n",
      "Preprocessed 2501/44146\n",
      "Preprocessed 2601/44146\n",
      "Preprocessed 2701/44146\n",
      "Preprocessed 2801/44146\n",
      "Preprocessed 2901/44146\n",
      "Preprocessed 3001/44146\n",
      "Preprocessed 3101/44146\n",
      "Preprocessed 3201/44146\n",
      "Preprocessed 3301/44146\n",
      "Preprocessed 3401/44146\n",
      "Preprocessed 3501/44146\n",
      "Preprocessed 3601/44146\n",
      "Preprocessed 3701/44146\n",
      "Preprocessed 3801/44146\n",
      "Preprocessed 3901/44146\n",
      "Preprocessed 4001/44146\n",
      "Preprocessed 4101/44146\n",
      "Preprocessed 4201/44146\n",
      "Preprocessed 4301/44146\n",
      "Preprocessed 4401/44146\n",
      "Preprocessed 4501/44146\n",
      "Preprocessed 4601/44146\n",
      "Preprocessed 4701/44146\n",
      "Preprocessed 4801/44146\n",
      "Preprocessed 4901/44146\n",
      "Preprocessed 5001/44146\n",
      "Preprocessed 5101/44146\n",
      "Preprocessed 5201/44146\n",
      "Preprocessed 5301/44146\n",
      "Preprocessed 5401/44146\n",
      "Preprocessed 5501/44146\n",
      "Preprocessed 5601/44146\n",
      "Preprocessed 5701/44146\n",
      "Preprocessed 5801/44146\n",
      "Preprocessed 5901/44146\n",
      "Preprocessed 6001/44146\n",
      "Preprocessed 6101/44146\n",
      "Preprocessed 6201/44146\n",
      "Preprocessed 6301/44146\n",
      "Preprocessed 6401/44146\n",
      "Preprocessed 6501/44146\n",
      "Preprocessed 6601/44146\n",
      "Preprocessed 6701/44146\n",
      "Preprocessed 6801/44146\n",
      "Preprocessed 6901/44146\n",
      "Preprocessed 7001/44146\n",
      "Preprocessed 7101/44146\n",
      "Preprocessed 7201/44146\n",
      "Preprocessed 7301/44146\n",
      "Preprocessed 7401/44146\n",
      "Preprocessed 7501/44146\n",
      "Preprocessed 7601/44146\n",
      "Preprocessed 7701/44146\n",
      "Preprocessed 7801/44146\n",
      "Preprocessed 7901/44146\n",
      "Preprocessed 8001/44146\n",
      "Preprocessed 8101/44146\n",
      "Preprocessed 8201/44146\n",
      "Preprocessed 8301/44146\n",
      "Preprocessed 8401/44146\n",
      "Preprocessed 8501/44146\n",
      "Preprocessed 8601/44146\n",
      "Preprocessed 8701/44146\n",
      "Preprocessed 8801/44146\n",
      "Preprocessed 8901/44146\n",
      "Preprocessed 9001/44146\n",
      "Preprocessed 9101/44146\n",
      "Preprocessed 9201/44146\n",
      "Preprocessed 9301/44146\n",
      "Preprocessed 9401/44146\n",
      "Preprocessed 9501/44146\n",
      "Preprocessed 9601/44146\n",
      "Preprocessed 9701/44146\n",
      "Preprocessed 9801/44146\n",
      "Preprocessed 9901/44146\n",
      "Preprocessed 10001/44146\n",
      "Preprocessed 10101/44146\n",
      "Preprocessed 10201/44146\n",
      "Preprocessed 10301/44146\n",
      "Preprocessed 10401/44146\n",
      "Preprocessed 10501/44146\n",
      "Preprocessed 10601/44146\n",
      "Preprocessed 10701/44146\n",
      "Preprocessed 10801/44146\n",
      "Preprocessed 10901/44146\n",
      "Preprocessed 11001/44146\n",
      "Preprocessed 11101/44146\n",
      "Preprocessed 11201/44146\n",
      "Preprocessed 11301/44146\n",
      "Preprocessed 11401/44146\n",
      "Preprocessed 11501/44146\n",
      "Preprocessed 11601/44146\n",
      "Preprocessed 11701/44146\n",
      "Preprocessed 11801/44146\n",
      "Preprocessed 11901/44146\n",
      "Preprocessed 12001/44146\n",
      "Preprocessed 12101/44146\n",
      "Preprocessed 12201/44146\n",
      "Preprocessed 12301/44146\n",
      "Preprocessed 12401/44146\n",
      "Preprocessed 12501/44146\n",
      "Preprocessed 12601/44146\n",
      "Preprocessed 12701/44146\n",
      "Preprocessed 12801/44146\n",
      "Preprocessed 12901/44146\n",
      "Preprocessed 13001/44146\n",
      "Preprocessed 13101/44146\n",
      "Preprocessed 13201/44146\n",
      "Preprocessed 13301/44146\n",
      "Preprocessed 13401/44146\n",
      "Preprocessed 13501/44146\n",
      "Preprocessed 13601/44146\n",
      "Preprocessed 13701/44146\n",
      "Preprocessed 13801/44146\n",
      "Preprocessed 13901/44146\n",
      "Preprocessed 14001/44146\n",
      "Preprocessed 14101/44146\n",
      "Preprocessed 14201/44146\n",
      "Preprocessed 14301/44146\n",
      "Preprocessed 14401/44146\n",
      "Preprocessed 14501/44146\n",
      "Preprocessed 14601/44146\n",
      "Preprocessed 14701/44146\n",
      "Preprocessed 14801/44146\n",
      "Preprocessed 14901/44146\n",
      "Preprocessed 15001/44146\n",
      "Preprocessed 15101/44146\n",
      "Preprocessed 15201/44146\n",
      "Preprocessed 15301/44146\n",
      "Preprocessed 15401/44146\n",
      "Preprocessed 15501/44146\n",
      "Preprocessed 15601/44146\n",
      "Preprocessed 15701/44146\n",
      "Preprocessed 15801/44146\n",
      "Preprocessed 15901/44146\n",
      "Preprocessed 16001/44146\n",
      "Preprocessed 16101/44146\n",
      "Preprocessed 16201/44146\n",
      "Preprocessed 16301/44146\n",
      "Preprocessed 16401/44146\n",
      "Preprocessed 16501/44146\n",
      "Preprocessed 16601/44146\n",
      "Preprocessed 16701/44146\n",
      "Preprocessed 16801/44146\n",
      "Preprocessed 16901/44146\n",
      "Preprocessed 17001/44146\n",
      "Preprocessed 17101/44146\n",
      "Preprocessed 17201/44146\n",
      "Preprocessed 17301/44146\n",
      "Preprocessed 17401/44146\n",
      "Preprocessed 17501/44146\n",
      "Preprocessed 17601/44146\n",
      "Preprocessed 17701/44146\n",
      "Preprocessed 17801/44146\n",
      "Preprocessed 17901/44146\n",
      "Preprocessed 18001/44146\n",
      "Preprocessed 18101/44146\n",
      "Preprocessed 18201/44146\n",
      "Preprocessed 18301/44146\n",
      "Preprocessed 18401/44146\n",
      "Preprocessed 18501/44146\n",
      "Preprocessed 18601/44146\n",
      "Preprocessed 18701/44146\n",
      "Preprocessed 18801/44146\n",
      "Preprocessed 18901/44146\n",
      "Preprocessed 19001/44146\n",
      "Preprocessed 19101/44146\n",
      "Preprocessed 19201/44146\n",
      "Preprocessed 19301/44146\n",
      "Preprocessed 19401/44146\n",
      "Preprocessed 19501/44146\n",
      "Preprocessed 19601/44146\n",
      "Preprocessed 19701/44146\n",
      "Preprocessed 19801/44146\n",
      "Preprocessed 19901/44146\n",
      "Preprocessed 20001/44146\n",
      "Preprocessed 20101/44146\n",
      "Preprocessed 20201/44146\n",
      "Preprocessed 20301/44146\n",
      "Preprocessed 20401/44146\n",
      "Preprocessed 20501/44146\n",
      "Preprocessed 20601/44146\n",
      "Preprocessed 20701/44146\n",
      "Preprocessed 20801/44146\n",
      "Preprocessed 20901/44146\n",
      "Preprocessed 21001/44146\n",
      "Preprocessed 21101/44146\n",
      "Preprocessed 21201/44146\n",
      "Preprocessed 21301/44146\n",
      "Preprocessed 21401/44146\n",
      "Preprocessed 21501/44146\n",
      "Preprocessed 21601/44146\n",
      "Preprocessed 21701/44146\n",
      "Preprocessed 21801/44146\n",
      "Preprocessed 21901/44146\n",
      "Preprocessed 22001/44146\n",
      "Preprocessed 22101/44146\n",
      "Preprocessed 22201/44146\n",
      "Preprocessed 22301/44146\n",
      "Preprocessed 22401/44146\n",
      "Preprocessed 22501/44146\n",
      "Preprocessed 22601/44146\n",
      "Preprocessed 22701/44146\n",
      "Preprocessed 22801/44146\n",
      "Preprocessed 22901/44146\n",
      "Preprocessed 23001/44146\n",
      "Preprocessed 23101/44146\n",
      "Preprocessed 23201/44146\n",
      "Preprocessed 23301/44146\n",
      "Preprocessed 23401/44146\n",
      "Preprocessed 23501/44146\n",
      "Preprocessed 23601/44146\n",
      "Preprocessed 23701/44146\n",
      "Preprocessed 23801/44146\n",
      "Preprocessed 23901/44146\n",
      "Preprocessed 24001/44146\n",
      "Preprocessed 24101/44146\n",
      "Preprocessed 24201/44146\n",
      "Preprocessed 24301/44146\n",
      "Preprocessed 24401/44146\n",
      "Preprocessed 24501/44146\n",
      "Preprocessed 24601/44146\n",
      "Preprocessed 24701/44146\n",
      "Preprocessed 24801/44146\n",
      "Preprocessed 24901/44146\n",
      "Preprocessed 25001/44146\n",
      "Preprocessed 25101/44146\n",
      "Preprocessed 25201/44146\n",
      "Preprocessed 25301/44146\n",
      "Preprocessed 25401/44146\n",
      "Preprocessed 25501/44146\n",
      "Preprocessed 25601/44146\n",
      "Preprocessed 25701/44146\n",
      "Preprocessed 25801/44146\n",
      "Preprocessed 25901/44146\n",
      "Preprocessed 26001/44146\n",
      "Preprocessed 26101/44146\n",
      "Preprocessed 26201/44146\n",
      "Preprocessed 26301/44146\n",
      "Preprocessed 26401/44146\n",
      "Preprocessed 26501/44146\n",
      "Preprocessed 26601/44146\n",
      "Preprocessed 26701/44146\n",
      "Preprocessed 26801/44146\n",
      "Preprocessed 26901/44146\n",
      "Preprocessed 27001/44146\n",
      "Preprocessed 27101/44146\n",
      "Preprocessed 27201/44146\n",
      "Preprocessed 27301/44146\n",
      "Preprocessed 27401/44146\n",
      "Preprocessed 27501/44146\n",
      "Preprocessed 27601/44146\n",
      "Preprocessed 27701/44146\n",
      "Preprocessed 27801/44146\n",
      "Preprocessed 27901/44146\n",
      "Preprocessed 28001/44146\n",
      "Preprocessed 28101/44146\n",
      "Preprocessed 28201/44146\n",
      "Preprocessed 28301/44146\n",
      "Preprocessed 28401/44146\n",
      "Preprocessed 28501/44146\n",
      "Preprocessed 28601/44146\n",
      "Preprocessed 28701/44146\n",
      "Preprocessed 28801/44146\n",
      "Preprocessed 28901/44146\n",
      "Preprocessed 29001/44146\n",
      "Preprocessed 29101/44146\n",
      "Preprocessed 29201/44146\n",
      "Preprocessed 29301/44146\n",
      "Preprocessed 29401/44146\n",
      "Preprocessed 29501/44146\n",
      "Preprocessed 29601/44146\n",
      "Preprocessed 29701/44146\n",
      "Preprocessed 29801/44146\n",
      "Preprocessed 29901/44146\n",
      "Preprocessed 30001/44146\n",
      "Preprocessed 30101/44146\n",
      "Preprocessed 30201/44146\n",
      "Preprocessed 30301/44146\n",
      "Preprocessed 30401/44146\n",
      "Preprocessed 30501/44146\n",
      "Preprocessed 30601/44146\n",
      "Preprocessed 30701/44146\n",
      "Preprocessed 30801/44146\n",
      "Preprocessed 30901/44146\n",
      "Preprocessed 31001/44146\n",
      "Preprocessed 31101/44146\n",
      "Preprocessed 31201/44146\n",
      "Preprocessed 31301/44146\n",
      "Preprocessed 31401/44146\n",
      "Preprocessed 31501/44146\n",
      "Preprocessed 31601/44146\n",
      "Preprocessed 31701/44146\n",
      "Preprocessed 31801/44146\n",
      "Preprocessed 31901/44146\n",
      "Preprocessed 32001/44146\n",
      "Preprocessed 32101/44146\n",
      "Preprocessed 32201/44146\n",
      "Preprocessed 32301/44146\n",
      "Preprocessed 32401/44146\n",
      "Preprocessed 32501/44146\n",
      "Preprocessed 32601/44146\n",
      "Preprocessed 32701/44146\n",
      "Preprocessed 32801/44146\n",
      "Preprocessed 32901/44146\n",
      "Preprocessed 33001/44146\n",
      "Preprocessed 33101/44146\n",
      "Preprocessed 33201/44146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 33301/44146\n",
      "Preprocessed 33401/44146\n",
      "Preprocessed 33501/44146\n",
      "Preprocessed 33601/44146\n",
      "Preprocessed 33701/44146\n",
      "Preprocessed 33801/44146\n",
      "Preprocessed 33901/44146\n",
      "Preprocessed 34001/44146\n",
      "Preprocessed 34101/44146\n",
      "Preprocessed 34201/44146\n",
      "Preprocessed 34301/44146\n",
      "Preprocessed 34401/44146\n",
      "Preprocessed 34501/44146\n",
      "Preprocessed 34601/44146\n",
      "Preprocessed 34701/44146\n",
      "Preprocessed 34801/44146\n",
      "Preprocessed 34901/44146\n",
      "Preprocessed 35001/44146\n",
      "Preprocessed 35101/44146\n",
      "Preprocessed 35201/44146\n",
      "Preprocessed 35301/44146\n",
      "Preprocessed 35401/44146\n",
      "Preprocessed 35501/44146\n",
      "Preprocessed 35601/44146\n",
      "Preprocessed 35701/44146\n",
      "Preprocessed 35801/44146\n",
      "Preprocessed 35901/44146\n",
      "Preprocessed 36001/44146\n",
      "Preprocessed 36101/44146\n",
      "Preprocessed 36201/44146\n",
      "Preprocessed 36301/44146\n",
      "Preprocessed 36401/44146\n",
      "Preprocessed 36501/44146\n",
      "Preprocessed 36601/44146\n",
      "Preprocessed 36701/44146\n",
      "Preprocessed 36801/44146\n",
      "Preprocessed 36901/44146\n",
      "Preprocessed 37001/44146\n",
      "Preprocessed 37101/44146\n",
      "Preprocessed 37201/44146\n",
      "Preprocessed 37301/44146\n",
      "Preprocessed 37401/44146\n",
      "Preprocessed 37501/44146\n",
      "Preprocessed 37601/44146\n",
      "Preprocessed 37701/44146\n",
      "Preprocessed 37801/44146\n",
      "Preprocessed 37901/44146\n",
      "Preprocessed 38001/44146\n",
      "Preprocessed 38101/44146\n",
      "Preprocessed 38201/44146\n",
      "Preprocessed 38301/44146\n",
      "Preprocessed 38401/44146\n",
      "Preprocessed 38501/44146\n",
      "Preprocessed 38601/44146\n",
      "Preprocessed 38701/44146\n",
      "Preprocessed 38801/44146\n",
      "Preprocessed 38901/44146\n",
      "Preprocessed 39001/44146\n",
      "Preprocessed 39101/44146\n",
      "Preprocessed 39201/44146\n",
      "Preprocessed 39301/44146\n",
      "Preprocessed 39401/44146\n",
      "Preprocessed 39501/44146\n",
      "Preprocessed 39601/44146\n",
      "Preprocessed 39701/44146\n",
      "Preprocessed 39801/44146\n",
      "Preprocessed 39901/44146\n",
      "Preprocessed 40001/44146\n",
      "Preprocessed 40101/44146\n",
      "Preprocessed 40201/44146\n",
      "Preprocessed 40301/44146\n",
      "Preprocessed 40401/44146\n",
      "Preprocessed 40501/44146\n",
      "Preprocessed 40601/44146\n",
      "Preprocessed 40701/44146\n",
      "Preprocessed 40801/44146\n",
      "Preprocessed 40901/44146\n",
      "Preprocessed 41001/44146\n",
      "Preprocessed 41101/44146\n",
      "Preprocessed 41201/44146\n",
      "Preprocessed 41301/44146\n",
      "Preprocessed 41401/44146\n",
      "Preprocessed 41501/44146\n",
      "Preprocessed 41601/44146\n",
      "Preprocessed 41701/44146\n",
      "Preprocessed 41801/44146\n",
      "Preprocessed 41901/44146\n",
      "Preprocessed 42001/44146\n",
      "Preprocessed 42101/44146\n",
      "Preprocessed 42201/44146\n",
      "Preprocessed 42301/44146\n",
      "Preprocessed 42401/44146\n",
      "Preprocessed 42501/44146\n",
      "Preprocessed 42601/44146\n",
      "Preprocessed 42701/44146\n",
      "Preprocessed 42801/44146\n",
      "Preprocessed 42901/44146\n",
      "Preprocessed 43001/44146\n",
      "Preprocessed 43101/44146\n",
      "Preprocessed 43201/44146\n",
      "Preprocessed 43301/44146\n",
      "Preprocessed 43401/44146\n",
      "Preprocessed 43501/44146\n",
      "Preprocessed 43601/44146\n",
      "Preprocessed 43701/44146\n",
      "Preprocessed 43801/44146\n",
      "Preprocessed 43901/44146\n",
      "Preprocessed 44001/44146\n",
      "Preprocessed 44101/44146\n"
     ]
    }
   ],
   "source": [
    "result = np.array([])\n",
    "result_all = np.array([])\n",
    "for ix, anek in enumerate(anekdots_array):\n",
    "    if ix % 100 == 0:\n",
    "        print(\"Preprocessed {}/{}\".format(ix + 1, len(anekdots_array)))\n",
    "    words = anek.split(' ')\n",
    "    result = np.unique(np.append(result, np.unique(words)))\n",
    "    if ix % 1000 == 0:\n",
    "        result_all = np.unique(np.append(result_all, result))\n",
    "        result = np.array([])\n",
    "\n",
    "result_all = np.unique(np.append(result_all, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'а', 'аа', ..., 'ёшкин', 'ёый', 'ёёъ'], dtype='<U61')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_count = {}\n",
    "for i in result:\n",
    "    result_count[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'а', 'ааааа', ..., 'яша', 'ящиками', ' '], dtype='<U32')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(result, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'канцелярию'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-2c772cd517f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manek\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manekdots_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manek\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mresult_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'канцелярию'"
     ]
    }
   ],
   "source": [
    "for ix, anek in enumerate(anekdots_array):\n",
    "    for word in anek.split(' '):\n",
    "        result_count[word] = result_count[word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шуток'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[34000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_np = np.zeros((len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34581,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
